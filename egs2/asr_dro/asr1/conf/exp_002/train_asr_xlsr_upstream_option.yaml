##
# Batching / Iterations / Epochs
####
num_workers: 4
batch_type: sorted
batch_size: 8
accum_grad: 4
patience: none
num_iters_per_epoch: 1000 # number of iterations per epoch
max_epoch: 30


##
# Model Selection
####
best_model_criterion:
-   - valid
    - loss
    - min
keep_nbest_models: 5


##
# Optimization / Scheduler
####
optim: adam
optim_conf:
    lr: 0.0001
    weight_decay: 0.000001
scheduler: warmuplr
scheduler_conf:
    warmup_steps: 25000


##
# Model Definition
####
input_size: 2048


frontend: s3prl
frontend_conf:
    frontend_conf:
        upstream: xls_r_300m # Note: If the upstream is changed, please change the input_size in the preencoder.
    download_dir: ./hub
    multilayer_feature: True

encoder: identity

decoder: none

unused_parameters: true
normalize: null
specaug: null
model_conf:
    ctc_weight: 1.0
    # length_normalized_loss: false

ctc_conf:
    ctc_type: builtin

##
# Initialization
####
init: xavier_uniform
# TODO
freeze_param: [
    "encoder.encoders.mask_emb", "encoder.encoders.feature_extractor",
    "encoder.encoders.post_extract_proj", "encoder.encoders.quantizer",
    "encoder.encoders.project_q", "encoder.encoders.encoder.pos_conv",
    "encoder.encoders.encoder.layers.0", "encoder.encoders.encoder.layers.1", "encoder.encoders.encoder.layers.2",
    "encoder.encoders.encoder.layers.3", "encoder.encoders.encoder.layers.4", "encoder.encoders.encoder.layers.5",
    "encoder.encoders.encoder.layers.6", "encoder.encoders.encoder.layers.7", "encoder.encoders.encoder.layers.8",
    "encoder.encoders.encoder.layers.9", "encoder.encoders.encoder.layers.10", "encoder.encoders.encoder.layers.11",
    "encoder.encoders.encoder.layers.12", "encoder.encoders.encoder.layers.13", "encoder.encoders.encoder.layers.14",
    "encoder.encoders.encoder.layers.15", "encoder.encoders.encoder.layers.16", "encoder.encoders.encoder.layers.17",
    "encoder.encoders.encoder.layers.18", "encoder.encoders.encoder.layers.19", "encoder.encoders.encoder.layers.20",
    "encoder.encoders.encoder.layers.21", "encoder.encoders.encoder.layers.22",
    "encoder.encoders.encoder.layer_norm", "encoder.encoders.layer_norm",
]


