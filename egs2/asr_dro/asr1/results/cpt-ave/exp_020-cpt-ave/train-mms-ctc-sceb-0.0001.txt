slurm submission log: 2024-09-23 10:52:24.699268
created following sbatch script: 

###############################

#!/bin/bash

#SBATCH --account=nlp
#SBATCH --cpus-per-task=4
#SBATCH --exclude=jagupard36,jagupard34
#SBATCH --gres=gpu:a6000:1
#SBATCH --job-name=train-mms-ctc-sceb-0.0001
#SBATCH --mail-type=ALL
#SBATCH --mail-user=bartelds@stanford.edu
#SBATCH --mem=64G
#SBATCH --open-mode=append
#SBATCH --output=results/exp_020/train-mms-ctc-sceb-0.0001.txt
#SBATCH --partition=jag-standard
#SBATCH --time=14-0

# activate your desired anaconda environment
. /nlp/scr/bartelds/miniconda3/envs/asr-dro/etc/profile.d/conda.sh ; conda activate /nlp/scr/bartelds/miniconda3/envs/asr-dro

# cd to working directory
cd .

# launch commands
srun --unbuffered run_as_child_processes 'source ../../../tools/activate_python.sh; make train-mms-ctc-sceb-0.0001'

###############################

submission to slurm complete!


###############################
slurm submission output

Submitted batch job 8580140



###############################

###############################
start time: 2024-09-23 11:23:01.261079
machine: jagupard33.stanford.edu
conda env: asr-dro
###############################
running following processes

	source ../../../tools/activate_python.sh; make train-mms-ctc-sceb-0.0001


###############################
command outputs: 


/bin/sh: 1: source: not found
./run_multi.sh --duration 1h --lid true --only_lid false --dumpdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_020 --expdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020 --asr_stats_dir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020 --specific_lang true --selected_languages lit --datasets fleurs --stage 11 --asr_tag train-mms-ctc-sceb-0.0001 --asr_config conf/exp_020/train_asr_mms_0.0001.yaml --batch_type language 
2024-09-23T11:23:01 (asr.sh:284:main) ./asr.sh --ngpu 1 --stage 11 --stop_stage 13 --nj 32 --inference_nj 4 --gpu_inference true --lang multilingual_1h__lid --inference_asr_model valid.loss.ave.pth --local_data_opts --duration 1h --lid true --only_lid false --multilingual true --nlsyms_txt data/local/nlsyms.txt --specific_lang true --selected_languages lit --datasets fleurs --nlsyms_txt data/local/nlsyms.txt --use_lm false --token_type char --feats_type raw --feats_normalize utterance_mvn --asr_config conf/exp_020/train_asr_mms_0.0001.yaml --inference_config conf/decode_asr.yaml --train_set train_1h_lid --valid_set dev_1h_lid --test_sets dev_1h_lid test_1h_lid --asr_tag train-mms-ctc-sceb-0.0001 --asr_stats_dir exp/asr_stats_multilingual_1h --local_score_opts true false normal --dumpdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_020 --expdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020 --asr_stats_dir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020 --batch_type language
2024-09-23T11:23:01 (asr.sh:322:main) Info: The valid_set 'dev_1h_lid' is included in the test_sets. '--eval_valid_set true' is set and 'dev_1h_lid' is removed from the test_sets
2024-09-23T11:23:01 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 16 
2024-09-23T11:23:01 (asr.sh:1310:main) Stage 11: ASR Training: train_set=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_020/raw/train_1h_lid, valid_set=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_020/raw/dev_1h_lid
2024-09-23T11:23:01 (asr.sh:1409:main) Generate '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/run.sh'. You can resume the process from stage 11 using this script
2024-09-23T11:23:01 (asr.sh:1413:main) ASR training started... log: '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/train.log'
2024-09-23 11:23:01,803 (launch:94) INFO: /nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/train.log' --log /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/multilingual_1h__lid_token_list/char/tokens.txt --non_linguistic_symbols data/local/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_020/raw/dev_1h_lid/wav.scp,speech,sound --valid_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001 --batch_type language --config conf/exp_020/train_asr_mms_0.0001.yaml --frontend_conf fs=16k --train_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_020/raw/train_1h_lid/wav.scp,speech,sound --train_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_020/raw/train_1h_lid/text,text,text --train_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/train/text_shape.char --valid_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_020/raw/dev_1h_lid/text,text,text --valid_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/valid/text_shape.char
2024-09-23 11:23:01,928 (launch:348) INFO: log file: /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/train.log
2024-09-23T11:39:34 (asr.sh:1483:main) Stage 12: Decoding: training_dir=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001
2024-09-23T11:39:34 (asr.sh:1511:main) Generate '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/decode_asr_asr_model_valid.loss.ave/run.sh'. You can resume the process from stage 12 using this script
2024-09-23T11:39:34 (asr.sh:1576:main) Decoding started... log: '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/decode_asr_asr_model_valid.loss.ave/org/dev_1h_lid/logdir/asr_inference.*.log'
2024-09-23T11:43:27 (asr.sh:1576:main) Decoding started... log: '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/decode_asr_asr_model_valid.loss.ave/test_1h_lid/logdir/asr_inference.*.log'
2024-09-23T11:47:29 (asr.sh:1623:main) Stage 13: Scoring
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --cleaner none --token_type char --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type char --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true --cleaner none
2024-09-23T11:47:36 (asr.sh:1713:main) Write cer result in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/decode_asr_asr_model_valid.loss.ave/org/dev_1h_lid/score_cer/result.txt
|      SPKR                   |      # Snt           # Wrd      |      Corr              Sub               Del              Ins              Err            S.Err      |
|      Sum/Avg                |        56             6874      |      37.4             47.0              15.6             22.4             85.0            100.0      |
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --cleaner none --token_type word --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type word --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true --cleaner none
2024-09-23T11:47:44 (asr.sh:1713:main) Write wer result in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/decode_asr_asr_model_valid.loss.ave/org/dev_1h_lid/score_wer/result.txt
|      SPKR                   |      # Snt           # Wrd      |      Corr              Sub               Del              Ins              Err            S.Err      |
|      Sum/Avg                |        56              949      |       3.1             94.0               3.0             24.9            121.8            100.0      |
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --cleaner none --token_type char --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type char --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true --cleaner none
2024-09-23T11:47:52 (asr.sh:1713:main) Write cer result in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/decode_asr_asr_model_valid.loss.ave/test_1h_lid/score_cer/result.txt
|      SPKR                   |      # Snt          # Wrd      |      Corr              Sub              Del             Ins              Err            S.Err      |
|      Sum/Avg                |        62            7338      |      37.4             46.9             15.8            24.2             86.8            100.0      |
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --cleaner none --token_type word --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type word --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true --cleaner none
2024-09-23T11:47:59 (asr.sh:1713:main) Write wer result in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/decode_asr_asr_model_valid.loss.ave/test_1h_lid/score_wer/result.txt
|      SPKR                   |      # Snt          # Wrd      |      Corr              Sub              Del             Ins              Err            S.Err      |
|      Sum/Avg                |        62            1004      |       2.6             93.7              3.7            28.8            126.2            100.0      |
2024-09-23T11:48:00 (score.sh:31:main) Linguistic scoring started
2024-09-23T11:48:00 (score.sh:32:main) local/score.sh true false normal /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001
[warning] linguistic information not loading
Parsing TER results in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/decode_asr_asr_model_valid.loss.ave/test_1h_lid/score_cer...
Parsing TER results in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/decode_asr_asr_model_valid.loss.ave/test_1h_lid/score_wer...
Parsing LID results in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_020/asr_train-mms-ctc-sceb-0.0001/decode_asr_asr_model_valid.loss.ave/test_1h_lid...
Traceback (most recent call last):
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/local/split_results.py", line 248, in <module>
    main(args)
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/local/split_results.py", line 222, in main
    lid_info = lid_parse(ref_txt_path, hyp_txt_path)
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/local/split_results.py", line 131, in lid_parse
    assert (
AssertionError: Can not find groundtruth of utterance (fleurs_lit_000350) in data/test_1h_lid/text.
make: *** [exp020.mk:154: train-mms-ctc-sceb-0.0001] Error 1
###############################
end time: 2024-09-23 11:48:02.642607
elapsed time: 0:25:01.381528
