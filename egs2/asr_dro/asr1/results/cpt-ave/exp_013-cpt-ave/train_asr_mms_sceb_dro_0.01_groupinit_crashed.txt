slurm submission log: 2024-08-22 18:43:40.117449
created following sbatch script: 

###############################

#!/bin/bash

#SBATCH --account=nlp
#SBATCH --cpus-per-task=2
#SBATCH --gres=gpu:a6000:1
#SBATCH --job-name=train_asr_mms_sceb_dro_0.01_groupinit
#SBATCH --mail-type=ALL
#SBATCH --mail-user=bartelds@stanford.edu
#SBATCH --mem=16G
#SBATCH --open-mode=append
#SBATCH --output=results/exp_013/train_asr_mms_sceb_dro_0.01_groupinit.txt
#SBATCH --partition=jag-standard
#SBATCH --time=14-0

# activate your desired anaconda environment
. /nlp/scr/bartelds/miniconda3/envs/asr-dro/etc/profile.d/conda.sh ; conda activate /nlp/scr/bartelds/miniconda3/envs/asr-dro

# cd to working directory
cd .

# launch commands
srun --unbuffered run_as_child_processes 'source ../../../tools/activate_python.sh; make train_asr_mms_sceb_dro_0.01_groupinit'

###############################

submission to slurm complete!


###############################
slurm submission output

Submitted batch job 8252916



###############################

###############################
start time: 2024-08-22 18:44:02.583032
machine: jagupard36.stanford.edu
conda env: asr-dro
###############################
running following processes

	source ../../../tools/activate_python.sh; make train_asr_mms_sceb_dro_0.01_groupinit


###############################
command outputs: 


/bin/sh: 1: source: not found
./run_multi.sh --duration 1h --lid true --only_lid false --dumpdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013 --expdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013 --asr_stats_dir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013 --specific_lang true --selected_languages nld,hrv,pol,slk,deu,ita,swa,myv,fra,ben,asm,lao,cym,urd,kir --datasets commonvoice,fleurs,M-AILABS,commonvoice,M-AILABS,commonvoice,commonvoice,commonvoice,fleurs,fleurs,commonvoice,fleurs,commonvoice,commonvoice,commonvoice --stage 11 --asr_tag train_asr_mms_sceb_dro_0.01_groupinit --asr_config conf/exp_013/train_asr_mms_sceb_dro_0.01_groupinit.yaml --batch_type language 
2024-08-22T18:44:02 (asr.sh:284:main) ./asr.sh --ngpu 1 --stage 11 --stop_stage 13 --nj 32 --inference_nj 4 --gpu_inference true --lang multilingual_1h__lid --inference_asr_model valid.loss.ave.pth --local_data_opts --duration 1h --lid true --only_lid false --multilingual true --nlsyms_txt data/local/nlsyms.txt --specific_lang true --selected_languages nld,hrv,pol,slk,deu,ita,swa,myv,fra,ben,asm,lao,cym,urd,kir --datasets commonvoice,fleurs,M-AILABS,commonvoice,M-AILABS,commonvoice,commonvoice,commonvoice,fleurs,fleurs,commonvoice,fleurs,commonvoice,commonvoice,commonvoice --nlsyms_txt data/local/nlsyms.txt --use_lm false --token_type char --feats_type raw --feats_normalize utterance_mvn --asr_config conf/exp_013/train_asr_mms_sceb_dro_0.01_groupinit.yaml --inference_config conf/decode_asr.yaml --train_set train_1h_lid --valid_set dev_1h_lid --test_sets dev_1h_lid test_1h_lid --asr_tag train_asr_mms_sceb_dro_0.01_groupinit --asr_stats_dir exp/asr_stats_multilingual_1h --local_score_opts true false normal --dumpdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013 --expdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013 --asr_stats_dir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013 --batch_type language
2024-08-22T18:44:02 (asr.sh:322:main) Info: The valid_set 'dev_1h_lid' is included in the test_sets. '--eval_valid_set true' is set and 'dev_1h_lid' is removed from the test_sets
2024-08-22T18:44:02 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 16 
2024-08-22T18:44:02 (asr.sh:1310:main) Stage 11: ASR Training: train_set=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid, valid_set=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid
2024-08-22T18:44:02 (asr.sh:1409:main) Generate '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/run.sh'. You can resume the process from stage 11 using this script
2024-08-22T18:44:02 (asr.sh:1413:main) ASR training started... log: '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log'
2024-08-22 18:44:03,053 (launch:94) INFO: /nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log' --log /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/multilingual_1h__lid_token_list/char/tokens.txt --non_linguistic_symbols data/local/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/wav.scp,speech,sound --valid_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit --batch_type language --config conf/exp_013/train_asr_mms_sceb_dro_0.01_groupinit.yaml --frontend_conf fs=16k --train_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid/wav.scp,speech,sound --train_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid/text,text,text --train_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/train/text_shape.char --valid_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/text,text,text --valid_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/valid/text_shape.char
2024-08-22 18:44:03,276 (launch:348) INFO: log file: /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log
run.pl: job failed, log is in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log
Command '['run.pl', '--name', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log', '--gpu', '1', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log', 'python3', '-m', 'espnet2.bin.asr_train', '--use_preprocessor', 'true', '--bpemodel', 'none', '--token_type', 'char', '--token_list', 'data/multilingual_1h__lid_token_list/char/tokens.txt', '--non_linguistic_symbols', 'data/local/nlsyms.txt', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/wav.scp,speech,sound', '--valid_shape_file', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/valid/speech_shape', '--resume', 'true', '--ignore_init_mismatch', 'false', '--fold_length', '80000', '--output_dir', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit', '--batch_type', 'language', '--config', 'conf/exp_013/train_asr_mms_sceb_dro_0.01_groupinit.yaml', '--frontend_conf', 'fs=16k', '--train_data_path_and_name_and_type', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid/wav.scp,speech,sound', '--train_shape_file', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/train/speech_shape', '--fold_length', '150', '--train_data_path_and_name_and_type', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid/text,text,text', '--train_shape_file', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/train/text_shape.char', '--valid_data_path_and_name_and_type', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/text,text,text', '--valid_shape_file', '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/valid/text_shape.char', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/launch.py", line 384, in <module>
    main()
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/launch.py", line 375, in main
    raise RuntimeError(
RuntimeError: 
################### The last 1000 lines of /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log ###################
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.8.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.8.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.8.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.8.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.9.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.10.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,050 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.11.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.12.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.13.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.14.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,051 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.15.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.16.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.17.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,052 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.18.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.19.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.20.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.21.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,053 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.22.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.attention.k_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.attention.k_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.attention.v_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.attention.v_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.attention.q_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.attention.q_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.attention.out_proj.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.attention.out_proj.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.feed_forward.intermediate_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.feed_forward.intermediate_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.feed_forward.output_dense.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.feed_forward.output_dense.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.final_layer_norm.weight.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,054 (abs_task:1280) INFO: Setting frontend.upstream.upstream.model.encoder.layers.23.final_layer_norm.bias.requires_grad = False
[jagupard36] 2024-08-22 18:44:34,472 (abs_task:1308) INFO: pytorch.version=2.1.0, cuda.available=True, cudnn.version=8902, cudnn.benchmark=False, cudnn.deterministic=True
[jagupard36] 2024-08-22 18:44:34,479 (abs_task:1309) INFO: Model structure:
ESPnetASRModel(
  (frontend): S3prlFrontend(
    (upstream): S3PRLUpstream(
      (upstream): UpstreamExpert(
        (model): Wav2Vec2Model(
          (feature_extractor): Wav2Vec2FeatureEncoder(
            (conv_layers): ModuleList(
              (0): Wav2Vec2LayerNormConvLayer(
                (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))
                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (activation): GELUActivation()
              )
              (1-4): 4 x Wav2Vec2LayerNormConvLayer(
                (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))
                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (activation): GELUActivation()
              )
              (5-6): 2 x Wav2Vec2LayerNormConvLayer(
                (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))
                (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (activation): GELUActivation()
              )
            )
          )
          (feature_projection): Wav2Vec2FeatureProjection(
            (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (projection): Linear(in_features=512, out_features=1024, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder): Wav2Vec2EncoderStableLayerNorm(
            (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(
              (conv): ParametrizedConv1d(
                1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16
                (parametrizations): ModuleDict(
                  (weight): ParametrizationList(
                    (0): _WeightNorm()
                  )
                )
              )
              (padding): Wav2Vec2SamePadLayer()
              (activation): GELUActivation()
            )
            (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (layers): ModuleList(
              (0-23): 24 x Wav2Vec2EncoderLayerStableLayerNorm(
                (attention): Wav2Vec2Attention(
                  (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                )
                (dropout): Dropout(p=0.1, inplace=False)
                (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (feed_forward): Wav2Vec2FeedForward(
                  (intermediate_dropout): Dropout(p=0.0, inplace=False)
                  (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)
                  (intermediate_act_fn): GELUActivation()
                  (output_dense): Linear(in_features=4096, out_features=1024, bias=True)
                  (output_dropout): Dropout(p=0.1, inplace=False)
                )
                (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
        )
      )
    )
    (featurizer): Featurizer()
  )
  (specaug): SpecAug(
    (time_warp): TimeWarp(window=5, mode=bicubic)
    (freq_mask): MaskAlongAxis(mask_width_range=[0, 27], num_mask=2, axis=freq)
    (time_mask): MaskAlongAxisVariableMaxWidth(mask_width_ratio_range=[0.0, 0.05], num_mask=10, axis=time)
  )
  (normalize): UtteranceMVN(norm_means=True, norm_vars=False)
  (preencoder): LinearProjection(
    (linear_out): Linear(in_features=1024, out_features=80, bias=True)
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (encoder): TransformerEncoder(
    (embed): Conv2dSubsampling2(
      (conv): Sequential(
        (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=18944, out_features=512, bias=True)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (12): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (13): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (14): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (15): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (16): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (17): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (18): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (19): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (20): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (21): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (22): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (23): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=512, out_features=332, bias=True)
    (ctc_loss): DROCTCLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Total Number of model parameters: 403.41 M
    Number of trainable parameters: 87.98 M (21.8%)
    Size: 351.9 MB
    Type: torch.float32
[jagupard36] 2024-08-22 18:44:34,479 (abs_task:1312) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0.001
)
[jagupard36] 2024-08-22 18:44:34,479 (abs_task:1313) INFO: Scheduler: None
[jagupard36] 2024-08-22 18:44:34,479 (abs_task:1322) INFO: Saving the configuration in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/config.yaml
[jagupard36] 2024-08-22 18:44:34,503 (asr:493) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[jagupard36] 2024-08-22 18:44:34,503 (abs_task:1691) WARNING: Reading /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid/utt2category
[jagupard36] 2024-08-22 18:44:34,518 (abs_task:1729) INFO: [train] dataset:
ESPnetDataset(
  speech: {"path": "/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid/wav.scp", "type": "sound"}
  text: {"path": "/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fdc003794c0>)
[jagupard36] 2024-08-22 18:44:34,518 (abs_task:1730) INFO: [train] Batch sampler: LanguageBatchSampler(N-batch=2112, batch_size=4, key_file=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/train/speech_shape, 
[jagupard36] 2024-08-22 18:44:34,518 (abs_task:1731) INFO: [train] mini-batch sizes summary: N-batch=2112, mean=4.0, min=4, max=4
[jagupard36] 2024-08-22 18:44:34,522 (asr:493) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[jagupard36] 2024-08-22 18:44:34,522 (abs_task:1691) WARNING: Reading /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/utt2category
[jagupard36] 2024-08-22 18:44:34,526 (abs_task:1729) INFO: [valid] dataset:
ESPnetDataset(
  speech: {"path": "/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/wav.scp", "type": "sound"}
  text: {"path": "/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fdc024aa880>)
[jagupard36] 2024-08-22 18:44:34,526 (abs_task:1730) INFO: [valid] Batch sampler: LanguageBatchSampler(N-batch=370, batch_size=4, key_file=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/valid/speech_shape, 
[jagupard36] 2024-08-22 18:44:34,526 (abs_task:1731) INFO: [valid] mini-batch sizes summary: N-batch=370, mean=4.0, min=4, max=4
[jagupard36] 2024-08-22 18:44:34,534 (asr:493) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[jagupard36] 2024-08-22 18:44:34,534 (abs_task:1691) WARNING: Reading /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/utt2category
[jagupard36] 2024-08-22 18:44:34,535 (abs_task:1729) INFO: [plot_att] dataset:
ESPnetDataset(
  speech: {"path": "/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/wav.scp", "type": "sound"}
  text: {"path": "/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fdc001a97f0>)
[jagupard36] 2024-08-22 18:44:34,536 (abs_task:1730) INFO: [plot_att] Batch sampler: UnsortedBatchSampler(N-batch=1456, batch_size=1, key_file=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/valid/speech_shape, 
[jagupard36] 2024-08-22 18:44:34,536 (abs_task:1731) INFO: [plot_att] mini-batch sizes summary: N-batch=3, mean=1.0, min=1, max=1
wandb: Currently logged in as: bartelds. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/wandb/run-20240822_184435-3l5evz0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run _juice2_scr2_bartelds_git_asr-dro_espnet_egs2_asr_dro_asr1
wandb: ⭐️ View project at https://wandb.ai/bartelds/asr-dro-set-2-update
wandb: 🚀 View run at https://wandb.ai/bartelds/asr-dro-set-2-update/runs/3l5evz0i
[jagupard36] 2024-08-22 18:44:38,255 (trainer:311) INFO: 1/30epoch started
/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
utt2category_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid/utt2category
/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid
utt2category_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/utt2category
/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid
Traceback (most recent call last):
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/asr_train.py", line 23, in <module>
    main()
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/asr_train.py", line 19, in main
    ASRTask.main(cmd=cmd)
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/tasks/abs_task.py", line 1157, in main
    cls.main_worker(args)
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/tasks/abs_task.py", line 1487, in main_worker
    cls.trainer.run(
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/train/trainer.py", line 317, in run
    all_steps_are_invalid = cls.train_one_epoch(
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/train/trainer.py", line 615, in train_one_epoch
    retval = model(**batch)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/asr/espnet_model.py", line 238, in forward
    encoder_out, encoder_out_lens = self.encode(speech, speech_lengths)
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/asr/espnet_model.py", line 380, in encode
    feats, feats_lengths = self._extract_feats(speech, speech_lengths)
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/asr/espnet_model.py", line 447, in _extract_feats
    feats, feats_lengths = self.frontend(speech, speech_lengths)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/asr/frontend/s3prl.py", line 99, in forward
    feats, feats_lens = self.upstream(input, input_lengths)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/s3prl/nn/upstream.py", line 209, in forward
    hidden_states = self.upstream(wavs_list)["hidden_states"]
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/s3prl/upstream/hf_wav2vec2/expert.py", line 39, in forward
    output_values = self.model(**input_values, output_hidden_states=True)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1823, in forward
    encoder_outputs = self.encoder(
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1148, in forward
    layer_outputs = layer(
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 981, in forward
    hidden_states, attn_weights, _ = self.attention(
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 631, in forward
    attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
  File "/nlp/scr/bartelds/miniconda3/envs/asr-dro/lib/python3.9/site-packages/torch/nn/functional.py", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 47.54 GiB of which 6.94 MiB is free. Process 2241258 has 37.92 GiB memory in use. Including non-PyTorch memory, this process has 9.60 GiB memory in use. Of the allocated memory 8.87 GiB is allocated by PyTorch, and 400.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: - 0.013 MB of 0.013 MB uploaded
wandb: \ 0.042 MB of 0.042 MB uploaded
wandb: 🚀 View run _juice2_scr2_bartelds_git_asr-dro_espnet_egs2_asr_dro_asr1 at: https://wandb.ai/bartelds/asr-dro-set-2-update/runs/3l5evz0i
wandb: ⭐️ View project at: https://wandb.ai/bartelds/asr-dro-set-2-update
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/wandb/run-20240822_184435-3l5evz0i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
[9, 9, 9, 9]
normalized dro_q:
q[group#deu]= 0.06274067610502243
q[group#pol]= 0.06429598480463028
q[group#asm]= 0.047440510243177414
q[group#cym]= 0.04576649144291878
q[group#ita]= 0.05402808263897896
q[group#kir]= 0.036529265344142914
q[group#myv]= 0.0489320382475853
q[group#nld]= 0.04395691305398941
q[group#slk]= 0.03536728769540787
q[group#swa]= 0.05256813392043114
q[group#urd]= 0.03832824528217316
q[group#ben]= 0.11968082934617996
q[group#fra]= 0.10236005485057831
q[group#hrv]= 0.10656622052192688
q[group#lao]= 0.14143915474414825
[9, 9, 9, 9]
normalized dro_q:
q[group#deu]= 0.06257685273885727
q[group#pol]= 0.0641278550028801
q[group#asm]= 0.047319069504737854
q[group#cym]= 0.0456496886909008
q[group#ita]= 0.05388839542865753
q[group#kir]= 0.036438051611185074
q[group#myv]= 0.04880646616220474
q[group#nld]= 0.043845124542713165
q[group#slk]= 0.0352792926132679
q[group#swa]= 0.0550529919564724
q[group#urd]= 0.038232047110795975
q[group#ben]= 0.11935928463935852
q[group#fra]= 0.10208649188280106
q[group#hrv]= 0.10628100484609604
q[group#lao]= 0.1410573422908783
[4, 4, 4, 4]
normalized dro_q:
q[group#deu]= 0.062405407428741455
q[group#pol]= 0.06395190954208374
q[group#asm]= 0.04719185829162598
q[group#cym]= 0.04552731662988663
q[group#ita]= 0.05649181082844734
q[group#kir]= 0.03634238243103027
q[group#myv]= 0.048674941062927246
q[group#nld]= 0.04372798278927803
q[group#slk]= 0.03518698364496231
q[group#swa]= 0.05490335822105408
q[group#urd]= 0.03813117742538452
q[group#ben]= 0.11902321875095367
q[group#fra]= 0.10180050134658813
q[group#hrv]= 0.10598285496234894
q[group#lao]= 0.14065837860107422
[4, 4, 4, 4]
normalized dro_q:
q[group#deu]= 0.06223385035991669
q[group#pol]= 0.06377585232257843
q[group#asm]= 0.047064557671546936
q[group#cym]= 0.04540485516190529
q[group#ita]= 0.05909653753042221
q[group#kir]= 0.036246638745069504
q[group#myv]= 0.04854332655668259
q[group#nld]= 0.04361075535416603
q[group#slk]= 0.035094600170850754
q[group#swa]= 0.0547536239027977
q[group#urd]= 0.0380302295088768
q[group#ben]= 0.1186869740486145
q[group#fra]= 0.10151435434818268
q[group#hrv]= 0.1056845411658287
q[group#lao]= 0.14025920629501343
# Accounting: time=45 threads=1
# Ended (code 1) at Thu Aug 22 18:44:48 PDT 2024, elapsed time 45 seconds

make: *** [exp013.mk:169: train_asr_mms_sceb_dro_0.01_groupinit] Error 1
###############################
end time: 2024-08-22 18:44:52.621124
elapsed time: 0:00:50.038092
slurm submission log: 2024-08-22 18:51:05.035120
created following sbatch script: 

###############################

#!/bin/bash

#SBATCH --account=nlp
#SBATCH --cpus-per-task=2
#SBATCH --gres=gpu:a6000:1
#SBATCH --job-name=train_asr_mms_sceb_dro_0.01_groupinit
#SBATCH --mail-type=ALL
#SBATCH --mail-user=bartelds@stanford.edu
#SBATCH --mem=16G
#SBATCH --open-mode=append
#SBATCH --output=results/exp_013/train_asr_mms_sceb_dro_0.01_groupinit.txt
#SBATCH --partition=jag-standard
#SBATCH --time=14-0

# activate your desired anaconda environment
. /nlp/scr/bartelds/miniconda3/envs/asr-dro/etc/profile.d/conda.sh ; conda activate /nlp/scr/bartelds/miniconda3/envs/asr-dro

# cd to working directory
cd .

# launch commands
srun --unbuffered run_as_child_processes 'source ../../../tools/activate_python.sh; make train_asr_mms_sceb_dro_0.01_groupinit'

###############################

submission to slurm complete!


###############################
slurm submission output

Submitted batch job 8252930



###############################

###############################
start time: 2024-08-22 22:48:08.316755
machine: jagupard33.stanford.edu
conda env: asr-dro
###############################
running following processes

	source ../../../tools/activate_python.sh; make train_asr_mms_sceb_dro_0.01_groupinit


###############################
command outputs: 


/bin/sh: 1: source: not found
./run_multi.sh --duration 1h --lid true --only_lid false --dumpdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013 --expdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013 --asr_stats_dir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013 --specific_lang true --selected_languages nld,hrv,pol,slk,deu,ita,swa,myv,fra,ben,asm,lao,cym,urd,kir --datasets commonvoice,fleurs,M-AILABS,commonvoice,M-AILABS,commonvoice,commonvoice,commonvoice,fleurs,fleurs,commonvoice,fleurs,commonvoice,commonvoice,commonvoice --stage 11 --asr_tag train_asr_mms_sceb_dro_0.01_groupinit --asr_config conf/exp_013/train_asr_mms_sceb_dro_0.01_groupinit.yaml --batch_type language 
2024-08-22T22:48:08 (asr.sh:284:main) ./asr.sh --ngpu 1 --stage 11 --stop_stage 13 --nj 32 --inference_nj 4 --gpu_inference true --lang multilingual_1h__lid --inference_asr_model valid.loss.ave.pth --local_data_opts --duration 1h --lid true --only_lid false --multilingual true --nlsyms_txt data/local/nlsyms.txt --specific_lang true --selected_languages nld,hrv,pol,slk,deu,ita,swa,myv,fra,ben,asm,lao,cym,urd,kir --datasets commonvoice,fleurs,M-AILABS,commonvoice,M-AILABS,commonvoice,commonvoice,commonvoice,fleurs,fleurs,commonvoice,fleurs,commonvoice,commonvoice,commonvoice --nlsyms_txt data/local/nlsyms.txt --use_lm false --token_type char --feats_type raw --feats_normalize utterance_mvn --asr_config conf/exp_013/train_asr_mms_sceb_dro_0.01_groupinit.yaml --inference_config conf/decode_asr.yaml --train_set train_1h_lid --valid_set dev_1h_lid --test_sets dev_1h_lid test_1h_lid --asr_tag train_asr_mms_sceb_dro_0.01_groupinit --asr_stats_dir exp/asr_stats_multilingual_1h --local_score_opts true false normal --dumpdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013 --expdir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013 --asr_stats_dir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013 --batch_type language
2024-08-22T22:48:09 (asr.sh:322:main) Info: The valid_set 'dev_1h_lid' is included in the test_sets. '--eval_valid_set true' is set and 'dev_1h_lid' is removed from the test_sets
2024-08-22T22:48:09 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 16 
2024-08-22T22:48:09 (asr.sh:1310:main) Stage 11: ASR Training: train_set=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid, valid_set=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid
2024-08-22T22:48:09 (asr.sh:1409:main) Generate '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/run.sh'. You can resume the process from stage 11 using this script
2024-08-22T22:48:10 (asr.sh:1413:main) ASR training started... log: '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log'
2024-08-22 22:48:11,597 (launch:94) INFO: /nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log' --log /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/multilingual_1h__lid_token_list/char/tokens.txt --non_linguistic_symbols data/local/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/wav.scp,speech,sound --valid_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit --batch_type language --config conf/exp_013/train_asr_mms_sceb_dro_0.01_groupinit.yaml --frontend_conf fs=16k --train_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid/wav.scp,speech,sound --train_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/train_1h_lid/text,text,text --train_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/train/text_shape.char --valid_data_path_and_name_and_type /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/dump/_exp_013/raw/dev_1h_lid/text,text,text --valid_shape_file /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/valid/text_shape.char
2024-08-22 22:48:12,685 (launch:348) INFO: log file: /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/train.log
2024-08-23T04:36:28 (asr.sh:1483:main) Stage 12: Decoding: training_dir=/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit
2024-08-23T04:36:28 (asr.sh:1511:main) Generate '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/run.sh'. You can resume the process from stage 12 using this script
2024-08-23T04:36:28 (asr.sh:1576:main) Decoding started... log: '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/org/dev_1h_lid/logdir/asr_inference.*.log'
2024-08-23T05:06:26 (asr.sh:1576:main) Decoding started... log: '/nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/test_1h_lid/logdir/asr_inference.*.log'
2024-08-23T05:36:52 (asr.sh:1623:main) Stage 13: Scoring
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --cleaner none --token_type char --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type char --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true --cleaner none
2024-08-23T05:37:03 (asr.sh:1713:main) Write cer result in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/org/dev_1h_lid/score_cer/result.txt
|      SPKR                    |       # Snt            # Wrd       |       Corr               Sub                Del               Ins                Err             S.Err       |
|      Sum/Avg                 |       1456             93550       |       77.8               9.7               12.4               3.6               25.8              98.6       |
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --cleaner none --token_type word --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type word --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true --cleaner none
2024-08-23T05:37:11 (asr.sh:1713:main) Write wer result in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/org/dev_1h_lid/score_wer/result.txt
|      SPKR                    |      # Snt             # Wrd       |      Corr               Sub               Del                Ins                Err              S.Err       |
|      Sum/Avg                 |      1456              14337       |      23.8              65.2              11.0                7.7               83.9               98.6       |
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --cleaner none --token_type char --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type char --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true --cleaner none
2024-08-23T05:37:20 (asr.sh:1713:main) Write cer result in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/test_1h_lid/score_cer/result.txt
|      SPKR                    |      # Snt            # Wrd       |      Corr                Sub               Del               Ins               Err             S.Err       |
|      Sum/Avg                 |      1471             93959       |      77.1               10.5              12.5               3.8              26.8              98.0       |
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --cleaner none --token_type word --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true
/nlp/scr/bartelds/miniconda3/envs/asr-dro/bin/python3 /juice2/scr2/bartelds/git/asr-dro/espnet/espnet2/bin/tokenize_text.py -f 2- --input - --output - --token_type word --non_linguistic_symbols data/local/nlsyms.txt --remove_non_linguistic_symbols true --cleaner none
2024-08-23T05:37:28 (asr.sh:1713:main) Write wer result in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/test_1h_lid/score_wer/result.txt
|      SPKR                    |      # Snt            # Wrd       |      Corr                Sub               Del               Ins               Err             S.Err       |
|      Sum/Avg                 |      1471             14434       |      22.8               65.7              11.5               7.4              84.5              98.0       |
2024-08-23T05:37:28 (score.sh:31:main) Linguistic scoring started
2024-08-23T05:37:28 (score.sh:32:main) local/score.sh true false normal /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit
[warning] linguistic information not loading
Parsing TER results in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/test_1h_lid/score_cer...
Parsing TER results in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/test_1h_lid/score_wer...
Parsing LID results in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/test_1h_lid...
2024-08-23T05:37:28 (score.sh:75:main) Write result in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/test_1h_lid/score_lid/few_shot/trained/scores.txt
Acc: 88.44%
2024-08-23T05:37:29 (score.sh:97:main) Write result in /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave/test_1h_lid/score_cer/few_shot/trained/result.txt
|       SPKR                     |       # Snt              # Wrd        |       Corr                 Sub                 Del                 Ins                 Err               S.Err        |
|       Sum/Avg                  |       1471               93959        |       77.1                10.5                12.5                 3.8                26.8                98.0        |
<!-- Generated by scripts/utils/show_asr_result.sh -->
# RESULTS
## Environments
- date: `Fri Aug 23 05:37:31 PDT 2024`
- python version: `3.9.19 (main, May  6 2024, 19:43:03)  [GCC 11.2.0]`
- espnet version: `espnet 202402`
- pytorch version: `pytorch 2.1.0`
- Git hash: `825accb575bef9be7a57f549589200babb711426`
  - Commit date: `Mon Aug 5 09:07:11 2024 -0700`

## /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit
### WER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.loss.ave/test_1h_lid|1471|14434|22.8|65.7|11.5|7.4|84.5|98.0|

### CER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|decode_asr_asr_model_valid.loss.ave/test_1h_lid|1471|93959|77.1|10.5|12.5|3.8|26.8|98.0|

### TER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
## /nlp/scr/bartelds/git/asr-dro/espnet/egs2/asr_dro/asr1/exp/_exp_013/asr_train_asr_mms_sceb_dro_0.01_groupinit/decode_asr_asr_model_valid.loss.ave
### WER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|org/dev_1h_lid|1456|14337|23.8|65.2|11.0|7.7|83.9|98.6|

### CER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
|org/dev_1h_lid|1456|93550|77.8|9.7|12.4|3.6|25.8|98.6|

### TER

|dataset|Snt|Wrd|Corr|Sub|Del|Ins|Err|S.Err|
|---|---|---|---|---|---|---|---|---|
2024-08-23T05:37:33 (asr.sh:1864:main) Successfully finished. [elapsed=24565s]
###############################
end time: 2024-08-23 05:37:39.068810
elapsed time: 6:49:30.752055
